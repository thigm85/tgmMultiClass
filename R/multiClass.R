#' Constructor for \code{multiClass} objects
#' 
#' \code{multiClass} objects hold final test set predictions performed by models.
#' 
#' \code{multiClass} objects hold predictions performed by a model over a number
#' of test sets generated according to some resampling of the data. A tag exist
#' to connect the predictions with the object that contains information about
#' the selected test sets. This allows results from different models to be 
#' compared since two \code{multiClass} objects with the same tag are guaranteed 
#' to be generated from the same test set points.
#' 
#' @param resample_indexes S3 object of class \code{datasetResample} with information
#'  about Class Labels and the data used using for training and predictions. Usually
#'  generated by the \code{generateTestIndexes} function.
#' @param prob List where each element contains a numeric vector with predictions for 
#'  a given test set. The numeric vector has the form 
#'  c(predictions_class1, predictions_class2, ..., predictions_classK) for 
#'  classification with K classes.
#' @param summary_validation Object of class \code{summaryValidation}, usually
#'  created by \code{SummaryValidationMetric} function. Default to NULL, when
#'  no validation step is necessary.
#' @param metric_name Character vector indicating the name of the metric used
#'  in the validation step. Default to NULL, when no validation step 
#'  is necessary. See the help of \code{evaluateProbClass} function to
#'  which metrics are currently available.
#' 
#' @return S3 object of class \code{multiClass}.
#' 
#' @family tgmMultiClass constructors
#' @seealso \code{\link{generateTestIndexes}}, 
#'  \code{\link{summaryValidation}}, 
#'  \code{\link{evaluateProbClass}}
#' @export
multiClass <- function(resample_indexes, prob, 
                       summary_validation = NULL, metric_name = NULL){
  
  object <- list(class_labels = mcGet(resample_indexes, "class_labels"), 
                 prob = prob, 
                 datasetResample_tag = mcGet(resample_indexes, "tag"),
                 summary_validation = summary_validation,
                 metric_name = metric_name)
  class(object) <- c("multiClass")
  return(object)
  
}

#' Extract info from \code{multiClass} objects
#' 
#' @export
mcGet.multiClass <- function(x, attr, i = NULL){
  
  if (attr == "prob"){ # probability predictions
    
    if (is.null(i)){
      return(x[["prob"]])  
    } else {
      if (i >= 1 & i <= length(x[["prob"]])){
        result <- matrix(x[["prob"]][[i]], ncol = length(x[["class_labels"]]), byrow = FALSE)
        colnames(result) <- x[["class_labels"]]
        return(result)
      } else {
        stop("index i out of range.")
      }
    }
    
  } else if (attr == "number_replicates"){ # number of prediction sets
    
    return(length(x[["prob"]]))
    
  } else if (attr == "class_labels"){ # class labels
    
    return(x[["class_labels"]])
    
  } else if (attr == "number_classes"){ # number of classes
    
    return(length(x[["class_labels"]]))
    
  } else if (attr == "tag"){ # resample indexes tag
    
    return(x[["datasetResample_tag"]])
    
  } else if (attr == "summary_validation"){ # Validation Summary
    
    summary_validation <- x[["summary_validation"]]
    if (is.null(summary_validation)){
      return(NULL)
    } else if (is.null(i)){
      return(summary_validation)
    } else if (i == "parameter_names"){
      parameter_names <- colnames(summary_validation)
      parameter_names <- parameter_names[-c(1, length(parameter_names))]
      return(parameter_names)
    } else {
      stop("Invalid i option for summary_validation")
    }
    
  } else if (attr == "metric_name"){ # Metric name used to evaluate models
    
    return(x[["metric_name"]])
    
  } else {
    stop(attr, " not found.")
  }
  
}